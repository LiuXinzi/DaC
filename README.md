## 计划（10.16-10.22）


## 控制回路
1. 前六个关节：leader机械臂-->python-get_angles-->python-write_angle-->socket-->树莓派-->控制follower机械臂 、
2. 夹爪： leader机械臂端口状态-->u2d2-->舵机
## 归一化
![image](https://github.com/LiuXinzi/DaC/assets/133741133/5700cd72-b7fb-4697-8dcc-4a24279898ee)\
qpos为采集的五十组数据里所有follower的角度的平均值和方差\
action为采集的五十组数据里所有leader的角度的平均值和方差\
pre是训练之前做的操作，post是网络输出角度后做的操作\
原文采集的数据都是小于10的数据，大多在1-2左右，我们的数据在100这个数量级，我不清楚这个归一化影响大不大，感觉我们机械臂训练出来的数据相差都不大，所以机械臂移动很小，不知道是不是这个原因
## 频率测试
本次测试主要使用三个时间作为频率数据
1. 读取时间： 指的是a机械臂角度的读取时间 使用wifi 在0.0015-0.002s 约 500-660HZ 使用网线没有较大变化
2. 通信时间： 指的是a机械臂角度读取到传递给b机械臂的时间 使用wifi在0.006-0.01s 约 100-167HZ 使用网线在0.003-0.0015s 在330-660HZ
3. 控制所需时间： 指的是b机械臂得到角度之后到开始控制需要的时间 使用wifi在0.005s左右 使用网线在0.001s\
使用wifi在静止的时候（忽略运动所需时间）：每一个while循环（读取通信加控制传递）在0.01s左右 使用网线在0.003-0.004s 通信速度变快
机械臂在得到角度之后需要跟随运动，最大运动速度在1999（机械臂速度参数最大）的时候，操作较慢的情况下，跟随运动在0.4s左右，操作较快需要跟随1s左右，不运动的时候时间可以忽略，这个时间目前使用command_wait_done函数去中和掉，也可以使用time.sleep(o.35)去等待运动

在数据传输过程中（不用command_wait）可能会有数据传输过去被覆盖，可以用通信队列尝试优化（未尝试）
## 夹爪夹取 --目前重心
01夹爪已经实现，且已经转移到树莓派内部，只需要树莓派同步即可同时同步夹爪和机械臂

连续： 学长说实验室有电机，让等他找找，找不到就自己买，准备买相同系列的电机可以用一个u2d2串联控制

专利目标： 01加连续，可以用手指转动电机来连续的同时也可以按钮控制01
## 推木块模仿学习  --暂时停止
单一动作： 从底部直接往框内推 训练6000次，采集数据11次，每次150帧 效果较好\
复杂动作： 从右边要先向上在向里面，且位置要找准 训练15000次，采集25次，每次300帧 效果比使用角度好很多，都可以找到目标推动，但是有时候推到木块一半过线就会停下

优化可能： 
1. 训练的误差一直未收敛过
2. 桌面的凹槽在摄像头里呈现黑色，有较大干扰
3. 把木块推进一个大的框在wrist机械臂眼里，在框外和框内可能效果类似 ，我觉得可以优化成 画一个小块，让物体盖住小块，这样可能好一点
# 单一机械臂控制
## 遥控系统 
### 原文&目前-思路对比
#### 原文的部署与遥控系统
1. ACT原文使用WindowX遥控操作关节更大的ViperX机械臂，其余的设置包括一个机器人笼，通过交叉钢电缆加固。总共有四个罗技C922x网络摄像头，每个设置480×640RGB图像。其中两个网络摄像头安装在跟随者机器人的手腕上，可以近距离观察抓持器。其余的两个摄像机分别安装在前面和顶部。远程操作和数据记录频率都为50HZ。

2. 原文考虑过使用VR控制器或摄像机捕捉到的手姿势映射到机器人的末端执行器姿势，即任务空间映射，最后没有采用的原因是精细操作需要在奇点处进行，反向运动学会出错。另一方面，联合空间映射保证了在联合限制范围内的高带宽控制，同时也需要更少的计算和减少延迟。原文只提及到通过关节角度同步来进行远程操控，但是根据视频可以看出关节同步效果好，延迟低。
#### 目前的部署与遥控系统
1. 设备部署：
   
    使用两台大象pro600机械臂，位于操作者面向方向，摄像头位于操作者左手边，正中间为机械臂工作区间（），follower机械臂旁边搭配一盏台灯，可以有效消除上方灯光影响（），leader机械臂上方用胶带捆绑一硬质物体用来保持自由移动
2. 末端执行器：
   
   leader机械臂采用手柄加按钮，手柄为3d打印材料，按钮为自锁按钮。follower机械臂末端执行器目前有两种，用来完成推动任务的长木棍末端，和用来抓取的夹爪末端。
   
3. 遥控系统：
   
   前六个关节角度：leader机械臂-->python-get_angles-->python-write_angle-->socket-->树莓派-->控制follower机械臂，读取需要时间，运动也需要时间，但是读取和运动并不同步。（即读取完并传递信号给follower机械臂为程序内进程，此时程序结束，之后树莓派控制机械臂不属于程序内，就会导致可叠加的延迟）因此如果只用while循环，不断进入循环会导致延迟不断增加，所以同步过程修改代码为等待程序运行完毕之后进入下一个while循环: \
只使用while循环，程序不断读取下一个位置，传递给树莓派之后继续读取，树莓派一直在接收，但是接收时间短控制时间长，会导致延迟叠加
```python
while True: 
   follower.write_angles(leader.get_angles(),1800#速度) 
   time.sleep(0.05)
```
使用wait_command_down,程序每次读取到下一个目标位置，等待树莓派控制机械臂运动结束后函数中止，进入下一次while循环读取下一个坐标，因此不会叠加延迟，不管时间多长都只会有最后一步的延迟
```python
while True: 
   follower.write_angles(leader.get_angles(),1800#速度) #发送所有角度给机械臂所有关节
   follower.wait_command_done()#等待到上一个命令完成为止，可以等到树莓派控制电机运动完毕
```
   夹爪（第七个电机）电机型号为：DYNAMIXEL XH540-W150 通过计算机通过leader机械臂的树莓派in端口的点位变化来控制舵机的旋转。首先按钮到计算机,线路为 树莓派GND---自锁按钮---树莓派in端口，当自锁按钮按下，电路导通，in端口获得1的输入，按钮打开线路断开，in端口状态转0。 之后计算机到舵机，大象机械臂带有读取树莓派in端口的api，计算机重复调用方法读取端口，当端口状态变化后连接u2d2旋转舵机指定角度。最后舵机到夹爪，夹爪通过3d打印，预留固定舵机的孔位，将舵机的砝码盘固定在夹爪主动件的圆盘上，舵机转动带动主动盘转动，之后带动连接件以及夹爪末端开合。

两个机械臂虽然每次启动都会调零，但是在实现中发现，当机械臂移动了一段时间之后，角度会有区别，如果这个问题可以解决的话，可以在leader机械臂旁边放置一块大小相似的物体，直接用leader去推动物体完成动作，这样也可以解决延迟问题（移动后需要等待才能判断follower机械臂是否移动到适当位置）。

文章里面是基于DYNAMIXEL XL430-W250。

## 算法原理&真机部署
### 算法原理
使用硬件收集用于测试的演示数据，将leader机械臂作为actions，observations由follower的关节位置与摄像机的图像传输组成。接下来根据当前的观察结果来预测未来的actions。这里的一个动作对应于下一个时间步中臂的目标关节位置。假设chunk的大小固定为k：每一个k个步骤都会收到一个观察结果，生成下一个k个操作，并依次执行这些操作。意味着任务的有效范围减少了k倍

Temporal Ensemble：为了避免一个新的环境被突然合并带来的剧烈运动，让不同的动作块重叠，通过指数加权来预测

网络包括一个一个CVAE编码器和一个CVAE解码器。CVAE编码器：仅用于训练CVAE解码器，测试的时候不需要。输入为当前的观察和动作序列作，预测样式变量z的分布的均值和方差，它被参数化为一个对角高斯分布。CVAE解码器：即策略，使用z条件和当前观测（图像+联合位置）来预测动作序列。在测试时将z设为先验分布的平均值，即从0到确定性解码。

参数：

learning rate 1e-5, batch size 8, encode layers 4, decoder layers 7, feedforward dimension 3200, hidden dimension 512, heads 8, chunk size 100 论文提及size为100的时候效果最好, beta 10, dropout 0.1
### 数据采集
#### 原文的数据收集
原文使用ALOHA远程操作来收集演示。根据任务的复杂性，每次需要8-14秒，控制频率为50Hz，400-700个时间步长，为每个任务记录了50个演示，除了螺纹尼龙搭扣有100个。搭载四个摄像机，两个机械臂，收集以下信息用于训练：

action sequence： 14维，（joint position + 0/1 ）*2

observations joints： 14维，（joint position + 0/1 ）*2

observations 4 RGB images： 4 * 480* 640 * 3
#### 目前的数据采集
目前使用syn遥控机械臂，以30HZ的频率收集拍照，使用大象的python api写入leader和follower的关节角度到rec.log文件中，读取文件使用两个list来保存两个机械臂分别的关节角度，之后与image一起打包为一组hdf5文件

action sequence： 6维，joint position

observations joints： 6维，joint position

observations top RGB images： 1 * 480* 640 * 3

目前暂时不采用夹爪，暂时先依旧采取无电机末端，结合两个摄像头的数据和更好的摇操来获得更好的数据，尝试效果，如果还是不行估计可能就是算法不能直接只改输入维度。\
我经过测试，给leader划分了一个类似的区间，希望可以在摇操的时候，不用等待follower到达，来获得更好的效果

#### 原因分析
1. 网络只修改了输入参数维度，可能需要调节内部结构（难度可能较大，我估计无法完成）
2. 数据流畅性，数据误差大，较多时候没有精准完成（），数据随机性大，训练任务较多
3. 摄像头信息不够？


